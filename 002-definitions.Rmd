# File type descriptors & definitions

This page provides definitions and guidance on the information that should be recorded for primary data files. Data that is clearly, simply and consistently described (named and defined) is much easier for users to identify, understand, use and share the data. This also ensures consistency across projects, inter-operability and is complementary to reproducible research practices. 

**If you will be working with a file type that is not described in these standards, please add a record.**

## Describing primary data file types
Biological data continue to be produced from an extensive array of assays and technologies. These data are often represented in unique file types and processed by specific software and algorithms. **Below are descriptors that we aim to use for each file type.**   

---

**File type:** This is the file format to be typically denoted by the file extension.  

**Description:** A brief description of the file format.  

**Compression:** The algorithm and/or method used to compress the file. \

**Permissions:** These are the user permission profiles for the groups and users that have access to the data, and the level of access \

- Category 1: (Highest): Lead PI (Alex Brown) and Chief Data Scientist (Jimmy Breen)
- Category 2: Lead PI, Chief Data Scientist and Data Science team
- Category 3: Lead PI, Chief Data Scientist, Data Science team and TKI IT Team
- Category 4: (Lowest): Public

**Access frequency:** How often this data type may require access. These descriptions are based on a subset of the [Google Cloud storage class descriptors](https://cloud.google.com/storage/docs/storage-classes#classes).

- **Standard:** Standard Storage is for data that is frequently accessed and/or stored for only brief periods of time. Standard data files should be able to be regenerated from Nearline or Archive data files without too much time or effort.
- **Nearline:** Nearline Storage is ideal for data you plan to read or modify on average once per month or less. Nearline Storage is appropriate for data backup and short-term archiving.
- **Archive:** highly durable storage for data archiving, backup, and disaster recovery. Only used for infrequently accessed data.

**Community access:** Are their community custodians for these data? If so, who are they? \

**Identifiable:** Could this data be used to identify an individual (YES/NO). \

**Location:** Location(s) where the data should be stored. \

**Notes:** Any additional information that would assist users of the data. \

**Sample:** A sample of the file data with descriptions of each field. Useful if this file type is not a widely used and documented standard.

## File type descriptor example

For example, the description of CGmap file format for DNA methylation data would look like this:

>**File type:** CGmap  
**Description:**  TSV file of stranded pileup base calls for cytosine positions in the reference genome DNA methylation data.  
**Compression:** gzip    
**Permissions:** Category 2  
**Access frequency:**  Nearline  
**Community access:**  TBD  
**Identifiable:**  No  
**Location:**  server_name::/location/of/data/  
**Notes:** This file type is output from [BSSeeker2](https://github.com/BSSeeker/BSseeker2) and used by [CGmap tools](https://cgmaptools.github.io/)  
**Sample:**  
>
>chr1	G	3000851	CHH	CC	0.1	1	10  
>chr1	C	3001624	CHG	CA	0.0	0	9  
>chr1	C	3001631	CG	CG	1.0	5	5  
>
>Format descriptions (columns):  
(1) chromosome \
(2) nucleotide on Watson (+) strand \
(3) position \
(4) context (CG/CHG/CHH) \
(5) dinucleotide-context (CA/CC/CG/CT) \
(6) methylation-level = #_of_C / (#_of_C + #_of_T) \
(7) #_of_C (methylated C, the count of reads showing C here) \
(8) = #_of_C + #_of_T (all Cytosines, the count of reads showing C or T here)


